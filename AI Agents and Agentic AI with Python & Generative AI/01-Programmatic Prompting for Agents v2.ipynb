{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23653c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "\n",
    "# %pip install litellm \n",
    "from litellm import completion # serves as the bridge between your code and the LLM, allowing you to send prompts and receive responses in a structured and efficient way\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935f8a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad30d6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! In functional programming, we often aim to write code that avoids side effects and focuses on transforming data through pure functions.\n",
      "\n",
      "Here's a simple implementation in Python that swaps the keys and values of a dictionary:\n",
      "\n",
      "```python\n",
      "def swap_dict_keys_values(d):\n",
      "    return {v: k for k, v in d.items()}\n",
      "\n",
      "# Example usage:\n",
      "original_dict = {'a': 1, 'b': 2, 'c': 3}\n",
      "swapped_dict = swap_dict_keys_values(original_dict)\n",
      "print(swapped_dict)  # Output: {1: 'a', 2: 'b', 3: 'c'}\n",
      "```\n",
      "\n",
      "This function, `swap_dict_keys_values`, uses a dictionary comprehension to iterate over the items of the input dictionary `d`, and constructs a new dictionary where each original value becomes a key, and each original key becomes a value.\n",
      "\n",
      "### Important Note\n",
      "- The function assumes that all values in the original dictionary are unique and hashable since these will become keys in the new dictionary. Duplicate values would lead to loss of data, as keys in a dictionary must be unique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/llms/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 9 fields but got 6: Expected `Message` - serialized value may not be as expected [input_value=Message(content=\"Certainl...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get response\"\"\"\n",
    "    response = completion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary.\"}\n",
    "]\n",
    "\n",
    "response = generate_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376deea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completions - openai native vs litellm\n",
    "# Unified interface to call multiple LLM providers (OpenAI, Anthropic, Azure, Mistral, etc.). Easy to switch providers\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"sk-...\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    ")\n",
    "\n",
    "\n",
    "import litellm\n",
    "\n",
    "litellm.set_api_key(\"openai\", \"sk-...\")\n",
    "\n",
    "response = litellm.completion(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
